{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0740d84e-ebd8-4944-aa87-9d58cc2d5efc",
      "metadata": {
        "id": "0740d84e-ebd8-4944-aa87-9d58cc2d5efc"
      },
      "source": [
        "# <FONT color =\"blue\">PREPROCESAMIENTO DE DATOS </FONT>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f81b938-1631-45f8-9f8f-dabb70dbd085",
      "metadata": {
        "id": "0f81b938-1631-45f8-9f8f-dabb70dbd085"
      },
      "source": [
        "![Preprocesamientoimagen.jpeg](attachment:c59780a8-b876-4d7c-bdcf-89d0e011f981.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4265f50c-f35f-4aea-a713-c18c3dfea600",
      "metadata": {
        "id": "4265f50c-f35f-4aea-a713-c18c3dfea600"
      },
      "source": [
        "### <FONT COLOR=\"blue\"> AUTOR </FONT>\n",
        "#### Kevin Andrés Rubiano Moreno\n",
        "#### Pregrado en Estadística \n",
        "#### Universidad Nacional de Colombia \n",
        "#### Bogotá, 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/KevinRubianoM/Diplomado_Ciencia_Datos/blob/main/Tareas/TAREA1KEVINRUBIANO.ipynb#scrollTo=zj-6PT3KV_Y7)"
      ],
      "metadata": {
        "id": "zj-6PT3KV_Y7"
      },
      "id": "zj-6PT3KV_Y7"
    },
    {
      "cell_type": "markdown",
      "id": "ae882878-c853-443f-9841-87f0cb2e3948",
      "metadata": {
        "id": "ae882878-c853-443f-9841-87f0cb2e3948"
      },
      "source": [
        "### <FONT COLOR=\"blue\"> PRESENTACIÓN DEL AUTOR </FONT>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b6f0f74-5766-4722-bee4-1cd7579715a1",
      "metadata": {
        "id": "7b6f0f74-5766-4722-bee4-1cd7579715a1"
      },
      "source": [
        "Kevin Andrés Rubiano Moreno es un estudiante de noveno semestre de pregrado en estadística, quien pretende con sus estudios enrriquecerse de herramientas estadísticas e informáticas útiles para la investigación sobre las causas y consecuencias del crimen y la delincuencia, y sobre las políticas de seguridad ciudadana. Además tiene interés en conocer posibles técnicas de inteligencia artificial para descubrir y prevenir el actuar de los criminales."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f51e0535-f44e-4af4-a97d-d12ff8da03bf",
      "metadata": {
        "id": "f51e0535-f44e-4af4-a97d-d12ff8da03bf"
      },
      "source": [
        "![FotoKevin2.jpeg](attachment:4fa2115f-c424-425f-897c-64328286a4da.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "716cee58-2c10-4054-afc6-195ad38fea74",
      "metadata": {
        "id": "716cee58-2c10-4054-afc6-195ad38fea74"
      },
      "source": [
        "## <FONT color=\"blue\"> Introducción al preprocesamiento de datos </FONT>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "070838bb-9a9c-4ee8-95f6-8a48691afebd",
      "metadata": {
        "id": "070838bb-9a9c-4ee8-95f6-8a48691afebd"
      },
      "source": [
        "La creciente cantidad de datos que actualmente se generan en diversos ámbitos ha despertado el interés de los investigadores en mejorar las técnicas para recolectarlos y almacenarlos de manera organizada, con el fin de obtener a partir de ellos conocimiento genuino. Sin embargo, algunos procesos de recolección son realizados con poco cuidado y varios fenómenos que generan datos son desorganizados por naturaleza. Al conjunto de datos recién obtenidos se le conoce como \"datos crudos\" (_raw data_ en inglés), que se carcateriza por estar desorganizado y ser difícilmente una fuente apropiada de información.  \n",
        "\n",
        "Uno de los pricipales problemas que representan los datos crudos para los científicos de datos es que no son precisos para entrenar modelos supervisados, ya que tienen muchos errores, inconsistencias y en algunos casos están incompletos. Estas condiciones los hacen poco viables o incluso inservibles para entrenar un modelo, pues por óptimo que sea el mismo, los datos con los que \"aprende\" no representan de manera correcta el fenómeno o la realidad a modelar.\n",
        "\n",
        "Con el fin de poder aumentar la efectividad de los modelos y sobre todo obtener información útil a partir de los datos recolectados, se deben llevar a cabo una serie de operaciones que sirven para arreglar, limpiar, traducir  y transformar el conjunto de datos; logrando con esto simplificar su análisis, prevenir conclusiones engañosas y sacar el mejor provecho de la información que contienen.  \n",
        "\n",
        "A esta serie de operaciones y técnicas previas al procesamiento de los datos se le conoce como preprocesamiento de datos o ingeniería de características, una disciplina que considera diferentes alternativas para mejorar el insumo de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f85266f2-718e-4603-81e8-88daa251f0d4",
      "metadata": {
        "id": "f85266f2-718e-4603-81e8-88daa251f0d4"
      },
      "source": [
        "## <FONT color=\"blue\"> Ejemplo: Técnicas de Normalización </FONT>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d85f9cad-7b17-4c6c-83a3-fae3c38e9ef5",
      "metadata": {
        "id": "d85f9cad-7b17-4c6c-83a3-fae3c38e9ef5"
      },
      "source": [
        "Los atributos están diseñados para funcionar en el ámbito que son usados aunque así tengan difícil interpretación estadística. Sin embargo, a veces se requiere que tengan un rango, media, dispersión, etc; distintos para que sean útiles y apropiados dentro de un modelo. Por esta razón, se utilizan operaciones de normalización sobre los atributos, que consisten en escalar los mismos.  \n",
        "  \n",
        "#### <font color= \"blue\">  Normalización mín-máx </font>\n",
        "\n",
        "Re-escalar las característizas bajo el mismo rango tiene particular importancia cuando se quieren calcular distancias, de este modo las variables con un gran rango no influyen de forma incorrecta en las predicciones del modelo. \n",
        "\n",
        "La normalización mín-máx consiste en asignar un nuevo rango de valores al atributo en cuestión, un nuevo mínimo y un nuevo máximo a partir del mínimo y el máximo originales conservando las relaciones entre los datos originales. \\[\\]\n",
        "\n",
        "Se usa la siguiente ecuación para normalizar los datos:\n",
        "\n",
        "$$ v'=\\frac{v-min_A}{max_A-min_A}(nuevo\\_max_A-nuevo\\_min_A)+nuevo\\_min_A$$\n",
        "\n",
        "Donde $A$ es el atributo en cuestión, $v$ es cada registro del atributo, y $v'$ es el nuevo valor del registro.\n",
        "\n",
        "Sin embargo, la presencia de datos atípicos puede ocasionar que la normalización mín-máx tenga un efecto contradictorio para el objetivo del estudio. Por ejemplo, en caso de que hayan datos atípicos los datos quedarían muy agrupados y esto limitaría la presición de la predicción del atributo.\\[\\] Por esto, se presenta la siguiente operación de normalización.    \n",
        "  \n",
        "#### <font color= \"blue\">  Normalización $z$-score  </font>\n",
        "Consiste en usar la distribución de los datos para simplificar su estructura. Esto se realiza restando la media de los datos a cada registro del atributo y dividiendolo entre la desviación estándar de los datos.\n",
        "$$v'=\\frac{v-media_A}{des\\_est_A}$$\n",
        "\n",
        "De este modo el nuevo atributo tiene media cero y varianza uno. \n",
        "\n",
        "Una alternativa robusta a datos atípicos para esta normalización, es usar la siguiente definición de la desviación estándar en vez de la original:\n",
        "\n",
        "$$s_A= \\frac{1}{n}\\sum_{i=1}^n |v_i-media_A|$$ \n",
        "\n",
        "#### <font color= \"blue\" >  Normalización de escala decimal </font>\n",
        "\n",
        "\n",
        "Este método de normalización consiste en dividir los registris del atributo entre una potencia de diez tal que el máximo valor absoluto del atributo sea menor o igual que 1. Esta es una forma de reducir el valor absoluto de un atributo $A$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ab9148d-4bf8-4023-8671-9a999322584e",
      "metadata": {
        "id": "3ab9148d-4bf8-4023-8671-9a999322584e"
      },
      "source": [
        "## <FONT color=\"blue\"> Ejercicio en Python </FONT>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b7bf616-86a0-407a-9627-7240bfb75a81",
      "metadata": {
        "id": "3b7bf616-86a0-407a-9627-7240bfb75a81"
      },
      "outputs": [],
      "source": [
        "# Importación de algunas librerías necesarias\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d595490a-b072-47c0-a52f-5be996082dcd",
      "metadata": {
        "id": "d595490a-b072-47c0-a52f-5be996082dcd",
        "outputId": "90d8a5e1-3870-4ab2-b98d-80e834cf7098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 502 entries, 0 to 501\n",
            "Data columns (total 7 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Date       502 non-null    object \n",
            " 1   Open       502 non-null    float64\n",
            " 2   High       502 non-null    float64\n",
            " 3   Low        502 non-null    float64\n",
            " 4   Close      502 non-null    float64\n",
            " 5   Adj Close  502 non-null    float64\n",
            " 6   Volume     502 non-null    int64  \n",
            "dtypes: float64(5), int64(1), object(1)\n",
            "memory usage: 27.6+ KB\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-01-02</td>\n",
              "      <td>86.050003</td>\n",
              "      <td>86.260002</td>\n",
              "      <td>85.349998</td>\n",
              "      <td>85.629997</td>\n",
              "      <td>78.766335</td>\n",
              "      <td>1197000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>84.849998</td>\n",
              "      <td>85.489998</td>\n",
              "      <td>84.809998</td>\n",
              "      <td>85.279999</td>\n",
              "      <td>78.444397</td>\n",
              "      <td>884800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-01-04</td>\n",
              "      <td>85.519997</td>\n",
              "      <td>85.680000</td>\n",
              "      <td>85.220001</td>\n",
              "      <td>85.330002</td>\n",
              "      <td>78.490387</td>\n",
              "      <td>438100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-01-05</td>\n",
              "      <td>85.599998</td>\n",
              "      <td>85.790001</td>\n",
              "      <td>85.330002</td>\n",
              "      <td>85.720001</td>\n",
              "      <td>78.849136</td>\n",
              "      <td>231300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-01-08</td>\n",
              "      <td>85.790001</td>\n",
              "      <td>85.800003</td>\n",
              "      <td>85.370003</td>\n",
              "      <td>85.480003</td>\n",
              "      <td>78.628372</td>\n",
              "      <td>382300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2018-01-09</td>\n",
              "      <td>85.900002</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>85.510002</td>\n",
              "      <td>85.889999</td>\n",
              "      <td>79.005508</td>\n",
              "      <td>765200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2018-01-10</td>\n",
              "      <td>85.239998</td>\n",
              "      <td>85.269997</td>\n",
              "      <td>84.760002</td>\n",
              "      <td>85.070000</td>\n",
              "      <td>78.251228</td>\n",
              "      <td>522000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2018-01-11</td>\n",
              "      <td>84.730003</td>\n",
              "      <td>84.860001</td>\n",
              "      <td>84.290001</td>\n",
              "      <td>84.519997</td>\n",
              "      <td>77.745308</td>\n",
              "      <td>627400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2018-01-12</td>\n",
              "      <td>84.849998</td>\n",
              "      <td>85.239998</td>\n",
              "      <td>84.629997</td>\n",
              "      <td>85.099998</td>\n",
              "      <td>78.278831</td>\n",
              "      <td>339600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2018-01-16</td>\n",
              "      <td>86.080002</td>\n",
              "      <td>86.269997</td>\n",
              "      <td>85.699997</td>\n",
              "      <td>86.199997</td>\n",
              "      <td>79.290649</td>\n",
              "      <td>603200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close   Volume\n",
              "0  2018-01-02  86.050003  86.260002  85.349998  85.629997  78.766335  1197000\n",
              "1  2018-01-03  84.849998  85.489998  84.809998  85.279999  78.444397   884800\n",
              "2  2018-01-04  85.519997  85.680000  85.220001  85.330002  78.490387   438100\n",
              "3  2018-01-05  85.599998  85.790001  85.330002  85.720001  78.849136   231300\n",
              "4  2018-01-08  85.790001  85.800003  85.370003  85.480003  78.628372   382300\n",
              "5  2018-01-09  85.900002  86.000000  85.510002  85.889999  79.005508   765200\n",
              "6  2018-01-10  85.239998  85.269997  84.760002  85.070000  78.251228   522000\n",
              "7  2018-01-11  84.730003  84.860001  84.290001  84.519997  77.745308   627400\n",
              "8  2018-01-12  84.849998  85.239998  84.629997  85.099998  78.278831   339600\n",
              "9  2018-01-16  86.080002  86.269997  85.699997  86.199997  79.290649   603200"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Importación de datos\n",
        "NESTLE = pd.read_table(\"NSRGY.csv\",delimiter=\",\",header=0)\n",
        "NESTLE.info()\n",
        "NESTLE.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac4c4980-a7ec-4afc-a560-6e9ca7eb6e27",
      "metadata": {
        "id": "ac4c4980-a7ec-4afc-a560-6e9ca7eb6e27",
        "outputId": "c356071d-403f-4f96-cb7e-877e8da7282a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-01-02</td>\n",
              "      <td>0.300741</td>\n",
              "      <td>0.299633</td>\n",
              "      <td>0.295033</td>\n",
              "      <td>0.288551</td>\n",
              "      <td>78.766335</td>\n",
              "      <td>1197000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>0.271111</td>\n",
              "      <td>0.280783</td>\n",
              "      <td>0.281485</td>\n",
              "      <td>0.279971</td>\n",
              "      <td>78.444397</td>\n",
              "      <td>884800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-01-04</td>\n",
              "      <td>0.287654</td>\n",
              "      <td>0.285435</td>\n",
              "      <td>0.291771</td>\n",
              "      <td>0.281196</td>\n",
              "      <td>78.490387</td>\n",
              "      <td>438100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-01-05</td>\n",
              "      <td>0.289630</td>\n",
              "      <td>0.288127</td>\n",
              "      <td>0.294531</td>\n",
              "      <td>0.290758</td>\n",
              "      <td>78.849136</td>\n",
              "      <td>231300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-01-08</td>\n",
              "      <td>0.294321</td>\n",
              "      <td>0.288372</td>\n",
              "      <td>0.295535</td>\n",
              "      <td>0.284874</td>\n",
              "      <td>78.628372</td>\n",
              "      <td>382300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2018-01-09</td>\n",
              "      <td>0.297037</td>\n",
              "      <td>0.293268</td>\n",
              "      <td>0.299047</td>\n",
              "      <td>0.294925</td>\n",
              "      <td>79.005508</td>\n",
              "      <td>765200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2018-01-10</td>\n",
              "      <td>0.280741</td>\n",
              "      <td>0.275398</td>\n",
              "      <td>0.280231</td>\n",
              "      <td>0.274822</td>\n",
              "      <td>78.251228</td>\n",
              "      <td>522000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2018-01-11</td>\n",
              "      <td>0.268148</td>\n",
              "      <td>0.265361</td>\n",
              "      <td>0.268440</td>\n",
              "      <td>0.261338</td>\n",
              "      <td>77.745308</td>\n",
              "      <td>627400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2018-01-12</td>\n",
              "      <td>0.271111</td>\n",
              "      <td>0.274663</td>\n",
              "      <td>0.276969</td>\n",
              "      <td>0.275558</td>\n",
              "      <td>78.278831</td>\n",
              "      <td>339600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2018-01-16</td>\n",
              "      <td>0.301481</td>\n",
              "      <td>0.299878</td>\n",
              "      <td>0.303813</td>\n",
              "      <td>0.302525</td>\n",
              "      <td>79.290649</td>\n",
              "      <td>603200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date      Open      High       Low     Close  Adj Close   Volume\n",
              "0  2018-01-02  0.300741  0.299633  0.295033  0.288551  78.766335  1197000\n",
              "1  2018-01-03  0.271111  0.280783  0.281485  0.279971  78.444397   884800\n",
              "2  2018-01-04  0.287654  0.285435  0.291771  0.281196  78.490387   438100\n",
              "3  2018-01-05  0.289630  0.288127  0.294531  0.290758  78.849136   231300\n",
              "4  2018-01-08  0.294321  0.288372  0.295535  0.284874  78.628372   382300\n",
              "5  2018-01-09  0.297037  0.293268  0.299047  0.294925  79.005508   765200\n",
              "6  2018-01-10  0.280741  0.275398  0.280231  0.274822  78.251228   522000\n",
              "7  2018-01-11  0.268148  0.265361  0.268440  0.261338  77.745308   627400\n",
              "8  2018-01-12  0.271111  0.274663  0.276969  0.275558  78.278831   339600\n",
              "9  2018-01-16  0.301481  0.299878  0.303813  0.302525  79.290649   603200"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Normalización MIN- MAX\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "min_max_scaler = MinMaxScaler()\n",
        "NESTLE.iloc[:,1:5] = min_max_scaler.fit_transform(NESTLE.iloc[:,1:5])\n",
        "NESTLE.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a902958f-a303-4530-bde9-b70206f80708",
      "metadata": {
        "id": "a902958f-a303-4530-bde9-b70206f80708"
      },
      "source": [
        "## <FONT color=\"blue\"> REFERENCIAS </FONT>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f700dcb-72dc-48f3-9cdb-2a079dbecfa4",
      "metadata": {
        "id": "9f700dcb-72dc-48f3-9cdb-2a079dbecfa4"
      },
      "source": [
        "* [scikit-learn: Preprocessing data](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing)\n",
        "* [Pre-procesamiento de datos con Python](https://www.jacobsoft.com.mx/es_mx/pre-procesamiento-de-datos-con-python/)\n",
        "* [Should I normalize/standardize/rescale the data?](http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}